| File | Summary |
| --- | --- |
| [code_instruct_example.py](https://github.com/facebookresearch/llama-recipes/tree/main/recipes/code_llama/code_instruct_example.py) | <details><summary>   This code is a PyTorch implementation of a transformer-based text generation model with safety checks for both user...</summary>  This code is a PyTorch implementation of a transformer-based text generation model with safety checks for both user and system prompts. It uses the Llama-Guard library for content safety checks and the AuditNLG library for sensitive topic checks. The model is trained on a dataset of text prompts and corresponding safe and unsafe responses. The code includes functions for handling safety checks, generating text, and performing inference with the model.<details> |
| [code_infilling_example.py](https://github.com/facebookresearch/llama-recipes/tree/main/recipes/code_llama/code_infilling_example.py) | <details><summary>   This code is a PyTorch implementation of a text generation model based on the Transformer architecture, with additional...</summary>  This code is a PyTorch implementation of a text generation model based on the Transformer architecture, with additional safety features to check the generated text for unsafe content. The code takes in various parameters such as the model name, maximum number of tokens to generate, and whether to use sampling or not. It first loads the model and tokenizer, then checks the user prompt for safety using a list of safety checkers. If the prompt is deemed unsafe, the code exits with an error status. If the prompt is safe, the code generates text using the model and checks the generated text for safety as well. The code also includes a timer to measure the end-to-end inference time.<details> |
| [code_completion_example.py](https://github.com/facebookresearch/llama-recipes/tree/main/recipes/code_llama/code_completion_example.py) | <details><summary>   This code is a PyTorch implementation of a text generation model based on the Transformer architecture, with additional...</summary>  This code is a PyTorch implementation of a text generation model based on the Transformer architecture, with additional safety features to check the generated text for unsafe content. The model is trained on a dataset of text and uses a tokenizer to convert the input text into a numerical representation for processing by the model. The model generates text by sampling from the probability distribution of the next token, and the generated text is then passed through a safety checker to check for unsafe content. The safety checker is based on a list of methods for checking the text, such as checking for profanity or sensitive topics, and the model is trained to avoid generating text that is deemed unsafe. The code includes options for customizing the model and the safety checker, such as the maximum number of tokens to generate, the temperature parameter for modulating the next token probabilities, and the repetition penalty for penalizing repeated tokens.<details> |
